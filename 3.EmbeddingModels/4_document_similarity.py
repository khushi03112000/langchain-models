from langchain_openai import OpenAIEmbeddings
from dotenv import load_dotenv
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

load_dotenv()

embedding = OpenAIEmbeddings(model='text-embedding-3-large', dimensions=300)

documents = [
    "Virat Kohli is an Indian cricketer known for his aggressive batting and leadership.",
    "MS Dhoni is a former Indian captain famous for his calm demeanor and finishing skills.",
    "Sachin Tendulkar, also known as the 'God of Cricket', holds many batting records.",
    "Rohit Sharma is known for his elegant batting and record-breaking double centuries.",
    "Jasprit Bumrah is an Indian fast bowler known for his unorthodox action and yorkers."
]

query = 'tell me about bumrah'

doc_embeddings = embedding.embed_documents(documents)
query_embedding = embedding.embed_query(query)

scores = cosine_similarity([query_embedding], doc_embeddings)[0]  //inside cosine_sim function you pass 2D vectors/arrays only and you get a similarity score in a 2D List so you can convert 2D list into simple list and store it in a variabl

index, score = sorted(list(enumerate(scores)),key=lambda x:x[1])[-1] //enumerating the list with [index,score] form and then sorting the list on score and returning the last key value pair as sorting results are in ascending order

print(query)
print(documents[index])
print("similarity score is:", score)




